{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf9fdd0",
   "metadata": {},
   "source": [
    "# Clasificador Bayesiano (Naive Bayes Classifier - NBC)\n",
    "\n",
    "En esta práctica se utilizará un modelo llamado \"Naive Bayes Classifier (NBC)\", el cual se usa comunmente para problemas de clasificación y en concreto se pueden aplicar para texto. Aplicaremos este modelo a un dataset, el cual, en base a una noticia, se le asigna una categoría a esta última."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a1dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6ee199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16495, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos el archivo\n",
    "noticias = pd.read_csv('C:\\\\Users\\\\Luis Carlos\\\\Documents\\\\CSVs\\\\noticias.csv')\n",
    "noticias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4574fe9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descripcion</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aunque parezca mentira, las emisiones de dióxi...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hubo un proyecto impulsado por la Unión Europe...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China ha confirmado la conclusión con éxito de...</td>\n",
       "      <td>tecnología</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>En su fructífera carrera como humorista, actor...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tras dos años de negociación entre la instituc...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16490</th>\n",
       "      <td>El vicepresidente del Grupo Atresmedia, Mauriz...</td>\n",
       "      <td>ocio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16491</th>\n",
       "      <td>En 1930, un millón de personas que vivían en l...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16492</th>\n",
       "      <td>El cable de cobre es un protagonista omniprese...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16493</th>\n",
       "      <td>Una inteligencia artificial detecta la enferme...</td>\n",
       "      <td>tecnología</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16494</th>\n",
       "      <td>El Gran Bosque del Norte tiene muchos nombres....</td>\n",
       "      <td>ocio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16495 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             descripcion   categoria\n",
       "0      Aunque parezca mentira, las emisiones de dióxi...     cultura\n",
       "1      Hubo un proyecto impulsado por la Unión Europe...     cultura\n",
       "2      China ha confirmado la conclusión con éxito de...  tecnología\n",
       "3      En su fructífera carrera como humorista, actor...     cultura\n",
       "4      Tras dos años de negociación entre la instituc...     cultura\n",
       "...                                                  ...         ...\n",
       "16490  El vicepresidente del Grupo Atresmedia, Mauriz...        ocio\n",
       "16491  En 1930, un millón de personas que vivían en l...     cultura\n",
       "16492  El cable de cobre es un protagonista omniprese...     cultura\n",
       "16493  Una inteligencia artificial detecta la enferme...  tecnología\n",
       "16494  El Gran Bosque del Norte tiene muchos nombres....        ocio\n",
       "\n",
       "[16495 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos la tabla\n",
    "noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a9743",
   "metadata": {},
   "source": [
    "Se observa que es una tabla con 16495 filas y 2 columnas. El problema es que cada fila contiene una noticia completa (como lo veremos a continuación) y a la hora de aplicar el clasificador bayesiano se vuelve un cálculo muy pesado, por lo que volveremos a cargar la tabla, pero esta vez nos quedaremos únicamente con las primeras 2000 noticias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bd15f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aunque parezca mentira, las emisiones de dióxido de carbono (CO2) y nitrógeno atmosféricos han actuado como fertilizante y han hecho que la Tierra sea hoy más verde que hace 30 años, pero se está acabando: Los ecosistemas terrestres se han saturado y se encaminan ya a una época de mayor calentamiento. Esta es la principal conclusión de un estudio internacional publicado en Nature Ecology & Evolution. El trabajo avisa que la Tierra va a pasar de una época de fertilización a otra de calentamiento aún mayor.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos la descripción de la primera noticia\n",
    "noticias.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7138a430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos nuevamente el archivo\n",
    "noticias = pd.read_csv('C:\\\\Users\\\\Luis Carlos\\\\Documents\\\\CSVs\\\\noticias.csv').iloc[:2000,]\n",
    "\n",
    "# Vemos la forma de la tabla cargada\n",
    "noticias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e79ba",
   "metadata": {},
   "source": [
    "Ahora sí, tenemos 2000 filas y 2 columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84d74bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cultura       1029\n",
       "tecnología     532\n",
       "ocio           439\n",
       "Name: categoria, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos cómo están distribuidas las categorías en las que se clasifican las noticias\n",
    "noticias.categoria.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8b0b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x19aecafcee0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizamos gráficamente esta proporción\n",
    "import seaborn as sns\n",
    "sns.displot(noticias['categoria'], height=2, aspect=2, color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a216f0",
   "metadata": {},
   "source": [
    "Observamos que las categorías no son balanceadas, la categoría de \"cultura\" tiende a sobresalir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95da22b1",
   "metadata": {},
   "source": [
    "Necesitamos ahora vectorizar el texto de cada noticia, por lo cual mandamos llamar la siguiente función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f779b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb0aca",
   "metadata": {},
   "source": [
    "Es necesario también eliminar cierto tipo de palabras llamadas \"stopwords\" (palabras vacías), las cuales son palabras que no tienen ningún contenido semántico. Por ejemplo, en la frase \"el perro ladra\" el artículo \"el\" no aporta ningún valor a la frase. Para eso me he descargado un archivo tipo json el cual contiene palabras específicas del idioma español, las cuales no aportan realmente información reelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68107a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('C:\\\\Users\\\\Luis Carlos\\\\Documents\\\\CSVs\\\\stopwords-es.json') as fname:\n",
    "    stopwords_es = json.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e7b07b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '_',\n",
       " 'a',\n",
       " 'actualmente',\n",
       " 'acuerdo',\n",
       " 'adelante',\n",
       " 'ademas',\n",
       " 'ademÃ¡s',\n",
       " 'adrede',\n",
       " 'afirmÃ³',\n",
       " 'agregÃ³',\n",
       " 'ahi',\n",
       " 'ahora',\n",
       " 'ahÃ\\xad',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'alguna',\n",
       " 'algunas',\n",
       " 'alguno',\n",
       " 'algunos',\n",
       " 'algÃºn']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos las primeras 30 palabras contenidas en este archivo\n",
    "stopwords_es[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3f2fcd",
   "metadata": {},
   "source": [
    "Es necesario también eliminar los acentos de las palabras, por lo cual, incluimos esto último en la siguiente función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "767bcdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador = TfidfVectorizer(strip_accents=\"unicode\", stop_words=stopwords_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03c0fea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forma de la tabla original\n",
    "noticias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77366b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luis carlos\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2000x17548 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 46857 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador.fit_transform(noticias.descripcion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce27957",
   "metadata": {},
   "source": [
    "Observamos que nos salta un \"warning\" al ejecutar esta última línea de código, por lo que procederemos a eliminarlo y volveremos a correr la línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7e6d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c3da418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x17548 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 46857 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador.fit_transform(noticias.descripcion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d08046",
   "metadata": {},
   "source": [
    "Ahora tenemos una matriz de 2000 filas y 17548 columnas. Esto es porque se vectorizó el texto de cada una de las filas (sin contar las palabras con acentos ni las stopwords)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef37a8",
   "metadata": {},
   "source": [
    "Dado que los vectorizadores devuelven una matriz sparse (escasa) creamos un transformador que las convierta a densas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad234515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "\n",
    "# http://rasbt.github.io/mlxtend/\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cb0e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29de00a",
   "metadata": {},
   "source": [
    "Scikit-Learn tiene 3 implementaciones del clasificador Naive Bayes: GaussianNB, BernoulliNB y MultinomialNB.\n",
    "Cada una de ellas se diferencia por cómo calcula las probabilidades de que cada elemento aparezca en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e50e2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mandamos llamar las librerías\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424d43a",
   "metadata": {},
   "source": [
    "Probaremos los 3 métodos y compararemos sus F1-Scores (medida de precisión que tiene un test) correspondientes para determinar cuál de las 3 fue la mejor opción. Recordemos que en el caso del F1-Score, entre más se acerque el valor a 1 es mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf641a9",
   "metadata": {},
   "source": [
    "### Para una Distribución Gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3108d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para una Distribución Gaussiana\n",
    "\n",
    "pipeline_gaussiano = make_pipeline(\n",
    "    vectorizador,\n",
    "    DenseTransformer(),\n",
    "    GaussianNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1378ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(stop_words=['0', '1', '2', '3', '4', '5', '6',\n",
       "                                             '7', '8', '9', '_', 'a',\n",
       "                                             'actualmente', 'acuerdo',\n",
       "                                             'adelante', 'ademas', 'ademÃ¡s',\n",
       "                                             'adrede', 'afirmÃ³', 'agregÃ³',\n",
       "                                             'ahi', 'ahora', 'ahÃ\\xad', 'al',\n",
       "                                             'algo', 'alguna', 'algunas',\n",
       "                                             'alguno', 'algunos', 'algÃºn', ...],\n",
       "                                 strip_accents='unicode')),\n",
       "                ('densetransformer', DenseTransformer()),\n",
       "                ('gaussiannb', GaussianNB())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustamos el modelo\n",
    "pipeline_gaussiano.fit(X=noticias.descripcion, y=noticias.categoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45c28109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cultura', 'cultura', 'tecnología', ..., 'cultura', 'cultura',\n",
       "       'cultura'], dtype='<U10')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacemos las predicciones\n",
    "pipeline_gaussiano.predict(noticias.descripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbf0485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traemos el F1-Score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_multietiqueta(estimador, X, y):\n",
    "    preds = estimador.predict(X)\n",
    "    return f1_score(y, preds, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f011dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65  , 0.65  , 0.62  , 0.6475, 0.64  ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluamos su F1-Score con 5 validaciones cruzadas\n",
    "cross_val_score(pipeline_gaussiano, noticias.descripcion, noticias.categoria, scoring=f1_multietiqueta,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "832a89f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En promedio, el F1-Score para el modelo de Distribución Gaussiana es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6415"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluamos el modelo\n",
    "print('En promedio, el F1-Score para el modelo de Distribución Gaussiana es:')\n",
    "cross_val_score(pipeline_gaussiano, noticias.descripcion, noticias.categoria, scoring=f1_multietiqueta,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d58b6d",
   "metadata": {},
   "source": [
    "Ahora hacemos lo mismo pero tomando en cuenta solamente las 1000 palabras más frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f454d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gaussiano = make_pipeline(\n",
    "    TfidfVectorizer(strip_accents=\"unicode\", stop_words=stopwords_es, max_features=1000),\n",
    "    DenseTransformer(),\n",
    "    GaussianNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfcfe843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5025, 0.49  , 0.5025, 0.495 , 0.455 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluamos su F1-Score con 5 validaciones cruzadas\n",
    "cross_val_score(pipeline_gaussiano, noticias.descripcion, noticias.categoria, scoring=f1_multietiqueta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb96e8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En promedio, el F1-Score para el modelo de Distribución Gaussiana con solamente las primeras 1000 palabras es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.489"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('En promedio, el F1-Score para el modelo de Distribución Gaussiana con solamente las primeras 1000 palabras es:')\n",
    "cross_val_score(pipeline_gaussiano, noticias.descripcion, noticias.categoria, scoring=f1_multietiqueta).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd54823",
   "metadata": {},
   "source": [
    "### Para una Distribución Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50bd1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para una distribución multinomial tomando únicamente las primeras 500 palabras más frecuentes:\n",
    "\n",
    "pipeline_multinomial = make_pipeline(\n",
    "    TfidfVectorizer(strip_accents=\"unicode\", stop_words=stopwords_es, max_features=500),\n",
    "    DenseTransformer(),\n",
    "    MultinomialNB(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0234d55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6625, 0.6775, 0.6825, 0.66  , 0.6875])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluamos su F1-Score\n",
    "cross_val_score(pipeline_multinomial, noticias.descripcion, noticias.categoria,\n",
    "                scoring=f1_multietiqueta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "977c273e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En promedio, el F1-Score para el modelo de Distribución Multinomial con solamente las primeras 1000 palabras es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.674"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('En promedio, el F1-Score para el modelo de Distribución Multinomial con solamente las primeras 1000 palabras es:')\n",
    "cross_val_score(pipeline_multinomial, noticias.descripcion, noticias.categoria,\n",
    "                scoring=f1_multietiqueta).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0d67a6",
   "metadata": {},
   "source": [
    "### Para una Distribución Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dda6241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizador_count = CountVectorizer(stop_words=stopwords_es, binary=True, \n",
    "                                     strip_accents=\"unicode\", max_features=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dfb4ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(binary=True, max_features=1500,\n",
       "                stop_words=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "                            '_', 'a', 'actualmente', 'acuerdo', 'adelante',\n",
       "                            'ademas', 'ademÃ¡s', 'adrede', 'afirmÃ³', 'agregÃ³',\n",
       "                            'ahi', 'ahora', 'ahÃ\\xad', 'al', 'algo', 'alguna',\n",
       "                            'algunas', 'alguno', 'algunos', 'algÃºn', ...],\n",
       "                strip_accents='unicode')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacemos el ajuste\n",
    "vectorizador_count.fit(noticias.descripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "780c90fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('emisiones', 497),\n",
       " ('carbono', 221),\n",
       " ('tierra', 1400),\n",
       " ('verde', 1454),\n",
       " ('30', 33),\n",
       " ('anos', 108),\n",
       " ('epoca', 523),\n",
       " ('principal', 1149),\n",
       " ('conclusion', 305),\n",
       " ('estudio', 560),\n",
       " ('internacional', 760),\n",
       " ('publicado', 1191),\n",
       " ('nature', 961),\n",
       " ('pasar', 1055),\n",
       " ('proyecto', 1183),\n",
       " ('impulsado', 731),\n",
       " ('union', 1432),\n",
       " ('europea', 564),\n",
       " ('llegaron', 831),\n",
       " ('manual', 865)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos 20 palabras junto con la cantidad de veces que aparecieron\n",
    "list(vectorizador_count.vocabulary_.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43deb1c9",
   "metadata": {},
   "source": [
    "Es decir, la paralbra \"emisiones\" apareció 497 veces, mientras que la palabra \"tierra\" apareció 1400 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13bc1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bernouilli = make_pipeline(\n",
    "    vectorizador_count,\n",
    "    DenseTransformer(),\n",
    "    BernoulliNB(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52d34656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6625, 0.655 , 0.6475, 0.6125, 0.655 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluamos su F1-Score\n",
    "cross_val_score(pipeline_bernouilli, noticias.descripcion, noticias.categoria, scoring=f1_multietiqueta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "938cdd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En promedio, el F1-Score para el modelo de Distribución Binomial con solamente las primeras 1500 palabras es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6465"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('En promedio, el F1-Score para el modelo de Distribución Binomial con solamente las primeras 1500 palabras es:')\n",
    "cross_val_score(pipeline_bernouilli, noticias.descripcion, noticias.categoria, scoring=f1_multietiqueta).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e3621",
   "metadata": {},
   "source": [
    "Como conclusión, para este dataset en específico, el modelo que arrojó mejores resultados fue el Clasificador Bayesiano para una Distribución Multinomial, el cual obtuvo una puntuación F1-Score de 0.674 (teniendo en cuenta que en este modelo tomamos únicamente las 500 palabras más frecuentes). El modelo que peor se ajustó a la realidad fue el segundo Clasificador Bayesiano para una Distribución Gaussiana, el cual sólo tomó en cuenta las 1000 palabras más frecuentes, con una puntuación F1-Score de 0.489."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
